\documentclass[a4paper]{article}

\usepackage[T1]{fontenc}	
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage{booktabs}
\usepackage{graphicx}
\usepackage{float}
\usepackage[margin=1in]{geometry}

\pagestyle{fancy}
\rhead{Home Assignment 2}
\lhead{Noah Hansson \& Kristoffer Nordström}

\title{Home Assignment 2 - FMSN50}
\author{Kristoffer Nordström, Noah Hansson}\author{Kristoffer Nordström \\ kr8245no-s@student.lu.se \and  Noah Hansson \\ no3822ha-s@student.lu.se}
\date{\today}


\setlength{\parskip}{0.7em}
\setlength{\parindent}{0pt}
\setlength{\floatsep}{6pt plus 1.0pt minus 2.0pt}
\setlength{\textfloatsep}{10pt plus 1.0pt minus 2.0pt}

\begin{document}
\maketitle
\newpage

\section*{1)}

All possible Self Avoiding Walks (SAW), $S_{n+m}(d)$, could be constructed by combining n-step SAWs with m-step SAWs, but all of these combination will not be self avoiding and thus is

\begin{equation}
    \label{eq:multiplicity}
    c_{n+m}(d)\leq c_n(d)c_m(d)
\end{equation}

\section*{2)}
From the result in section 1 we can prove that the logarithm of $c_n$ is subadditive:
\begin{equation}
    c_{n+m}(d) \leq c_n(d)c_m(d) \rightarrow log(c_{n+m}) \leq log(c_n(d)c_m(d)) = log(c_n(d)) + log(c_m(d))
\end{equation}

 Therefore, we can use \textit{Fekete's Lemma} to prove that $\lim_{n\rightarrow\infty} \frac{log(c_n(d))}{n}$ exists. Since $e(x)$ is a well defined function for all $x$, we know that the limit $\lim_{n\rightarrow\infty} exp(\frac{log(c_n(d))}{n}) = \lim_{n\rightarrow\infty} c_n(d)^{1/n}$ exists. 

\section*{3)}
A first approach for estimating $c_n(2)$ is to generate $N$ random walks in $\mathbb{Z}^2$, and then count the amount of walks $N_{SA}$ that randomly happen to be self-avoiding. To sample random walks $X_i^{0:n}$ we draw 
\begin{equation}
    X_i^{n+1} \sim g_{n+1}(x_{n+1}|X^{0:n})
\end{equation}
where $g_{n+1}$ is the probability density of choosing a neighbouring point to the last point $X_i^n$. Since the walk is purely random, $g_{n+1}(x_{n+1}|X^{0:n}) = g_{n+1}(x_{n+1}|X^n)$ simply amounts to uniformly choosing a neigbour of $X^n$ with probability $p = \frac{1}{2d}$.

For every step each walk gets assigned a weight based on the probability of the walk resulting in this particular walk. The weights are defined such that:
\begin{equation}
    \sum_{i = 1}^N\frac{\omega_n^i}{\sum_{l=1}^N\omega_n^l}\phi(X_i^{0:n}) \approx \mathbb{E}_{f_n}(\phi(X_{0:n})) 
\end{equation}

All walks are at $n = 0$ assigned equal weights: $\omega_0^i = 1$, $\forall i$, and are then for each step updated as:
\begin{equation}
    \label{eq:weights}
    \omega_{n+1}^i = \frac{z_{n+1}(X_i^{0:n+1})}{z_{n}(X_i^{0:n})g_{n+1}(x_{n+1}|X^{0:n})} * \omega_n^i
\end{equation}
where $z_n(X_i^{0:n})$ is an indicator function with value $1$ if the walk if self-avoiding or $0$ otherwise.

When the weights are updated two things can happen: either the walk has collided with itself and the weight is set to $0$, or the walk continues to be self-avoiding and is divided by the probability density. Therefore, the weights are either $\omega_n^i = (2d)^n$ or zero.

From this, we can then find approximations of $c_n(d)$ by simulating N walks and then finding the mean of all weights, since this amounts to:
\begin{equation}
    c_n(d) = (2d)^n*\frac{N_{SA}}{N} = \sum_{i = 1}^N\frac{\omega_n^i}{\sum_{l=1}^N\omega_n^l}
\end{equation}

Using $N = 10^4$ approximations of $c_n(2)$ are presented in table XXX.

\begin{table}[H]
    \centering
    \caption{Approximations of $c_n(2)$ for different n, with a $95\%$ confidence interval by sampling random walks.
    \label{tab:random_walks_results}
    \include{tables/random_walk_results}
\end{table}

\section*{7)}

 To find a bound for $\mu_d$ we can use the following equation:

\begin{equation}
    \label{eq:limit}
     \mu_d = \lim_{n \to \infty} c_d(n)^{1/n}
\end{equation}


First, we begin by finding an upper and a lower bound for $c_d(n)$. For the upper bound, we know that the maximum amount of self-avoiding random walks is bounded by the maximum possible amount of random walks, $(2d)^n$. Furthermore, we can extend this reasoning to also exclude the walks when a step simply retraces its previous step, reducing the upper bound of self-avoiding random walks to $(2d-1)^n$. For the lower bound, we know that all random walks that only step in positive directions will be self-avoiding. Therefore we find a lower bound of $d^n$. This gives us the expression \begin{equation}
    d^n \leq c_d(n) \leq (2d-1)^n
\end{equation}
We then take the limit as in equation (\ref{eq:limit}) of the bounds as well as $c_n(d)$. This gives us:
\begin{equation}
    \lim_{n \to \infty} (d^n)^{1/n} \leq \lim_{n \to \infty} c_n(d)^{1/n} \leq \lim_{n \to \infty} ((2d-1)^n)^{1/n}
\end{equation}
Simplifying and inserting equation (\ref{eq:limit}) gives us:
\begin{equation}
    d \leq \mu_d \leq 2d-1
\end{equation}

\section*{8)}
We can find a lower bound for $A_d$ when $d \geq 5$ by using the equation:
\begin{equation}
    \label{eq:cd}
    c_n(d) \sim 
    \begin{cases}
        A_d\mu_d^nn^{\gamma-1}, \quad d = 1, 2, 3, d \geq 5 \\
        A_d\mu_d^n\log(n)^{1/4}, \quad d = 4
    \end{cases}, \quad as \; n \to \infty
\end{equation}

For any integers $a$ and $b$ such that $a \to \infty$ and $b \to \infty$ we can plug in equation (\ref{eq:cd}) to equation (\ref{eq:multiplicity}) to get:
\begin{equation}
    A_d\mu_d^{a+b}(a+b)^{\gamma_d-1} = c_{n+m}(d)\leq c_n(d)c_m(d) = A_d\mu_d^aa^{\gamma-1}A_d\mu_d^bb^{\gamma-1}
\end{equation}
Since it is known that $\gamma = 1$ for $d \geq 5$ we can simplify this to:
\begin{equation}
    A_d\mu^{a+b} \leq A_d^2\mu^{a+b} \implies A_d \geq 1
\end{equation}

\end{document}
